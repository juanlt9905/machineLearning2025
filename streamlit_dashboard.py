import streamlit as st

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pickle




#Cargar Datos

#datos_diabetes = pd.read_csv('datasets/diabetes_012_health_indicators_BRFSS2015.csv')
datos_diabetes = pd.read_csv('/home/juan/machineLearning2025/datasets/diabetes_012_health_indicators_BRFSS2015.csv')
#Crear la columna diabetes_01 que unifique prediabetes con diabetes
datos_diabetes['diabetes_01'] = datos_diabetes['Diabetes_012']
datos_diabetes['diabetes_01'] = datos_diabetes['diabetes_01'].replace(2,1)

#Reparar nombres de columnas. Se usa el formato loweCamelCase para el nombre de las caracteristicas.

new_col_names = []

for name in datos_diabetes.columns:
    # Luego, pon todas las letras en min칰sculas
    name_lowered_first_letter = name[0].lower() + name[1:]
    # Elimina los espacios al principio y al final
    name_stripped = name_lowered_first_letter.strip()
    # Por 칰ltimo, reemplaza los espacios entre palabras por guiones bajos
    name_no_spaces = name_stripped.replace(' ', '_')
    # Agrega el nuevo nombre a la lista de nuevos nombres de columna
    new_col_names.append(name_no_spaces)

datos_diabetes.columns = new_col_names

datos_diabetes = datos_diabetes.rename(columns={'bMI':'bmi'})

#Definicion de datos enteros.
for col in datos_diabetes.columns:
    #if datos_diabetes[col].dtype == 'float64':
    datos_diabetes[col] = datos_diabetes[col].astype(int)

import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# --- Configuraci칩n de la P치gina ---
st.set_page_config(
    page_title="Dashboard de Diabetes",
    page_icon="游뽘",
    layout="wide" # 'wide' aprovecha mejor el espacio en pantalla
)


# --- Barra Lateral de Navegaci칩n ---
st.sidebar.title("Navegaci칩n")
page = st.sidebar.radio("Ve a la secci칩n:", 
    [
        "Introducci칩n", 
        "An치lisis Exploratorio",
        "Balanceo de clases",
        "Importancia de caracter칤sticas", 
        "Resultados: 츼rboles de decisi칩n",
        "Resultados: Random Forest",
        "Resultados: Perceptr칩n multicapa",
        "Resultados: Random Forest balanceado",
        "Resultados: XGBoost",
        "Conclusiones Generales"
    ]
)



# --- T칤tulo y Descripci칩n del Dashboard ---
st.title('An치lisis de pacientes con Diabetes en EU')

if page == "Introducci칩n":

    st.write("""
    Dataset de origen

    El Sistema de Vigilancia de Factores de Riesgo en el Comportamiento (BRFSS) se encarga de realizar 
    encuestas telef칩nicas relacionadas con la salud de los residentes de EE.UU., relativos a sus comportamientos 
    de riesgos para su salud, como lo son enfermedades cr칩nicas, h치bitos de preveenci칩n de enfermedades y uso de 
    servicios de salud. 

    https://www.cdc.gov/brfss/annual_data/annual_data.htm
             
    Objetivo de trabajar con este dataset:


    * 쮺u치les son las variables m치s importantes para porder clasificar a los pacientes respecto a riesgo de  diabetes?

    * 쯃a informaci칩n recopilada por la BRFSS puede clasificar pacientes con diabetes y pacientes sanos ?
             

    Dataset desbalanceado. 22 variables. Variaable predictora: diabetes.

    Diabetes_012 -> 0 no diabetes, 1 prediabetes, 2 diabetes. Varliable Categ칩rica.

    HighBP-> Hipertension. Variable Boolena.

    HighChol -> COlesterol alto. Variable Booleana.

    CholCheck-> Chequeo de colesterol los ultimos 5 a침os. Variable Booleana.

    BMI -> Indice de masa corporal. Variable discreta.

    Smoker ->Ha fumado al menos 100 cigarrros en su vida. Variable booleana.

    Stroke -> Derrame cerebral. Variable booleana.

    HeartDiseaseorAttack -> infarto coronario o infarto al miocardio. Variable booleana.

    PhysActivity -> Actividad fisica los ultimos 30 dias. Variable booleana.

    Fruits -> Consume al menos 1 fruta al dia. Variable booleana.

    Veggies -> Consume vegetales al menos 1 vez al dia. Variable booleana.

    HvyAlcoholConsump -> Hombres que toman mas de 14 bebidas alcoholicas por semana, mujeres mas de 7. Variable booleana.

    AnyHealthcare-> Tiene algun seguro m칠dico. Variable booleana.

    NoDocbcCost-> En el ultimo a침o, no visito a un doctor debido a no poder costear los servicios m칠dicos. Variable booleana.

    GenHlth -> Opinion de salud general, tu salud general es? Escala 1-5. Variable categ칩rica.

    MentHlth -> Por cuantos dias durante el ultimo mes (1-30) no tuviste una salud buena?. Variable categ칩rica. 

    PhysHlth -> Por cuantos dias durante el ultimo mes (1-30) tu salud no fue buena?. Variable categ칩rica.

    DiffWalk -> TIenes dificultades para caminar o subir escaleras?. Variable booleana.

    Sex -> 0=Femenino, 1= Masculino. Variable boolena.

    Age ->  escala del 1-13, 1= 18-24, 2=25-29, 3=30-34, 4=35-39, 5=40-44, 6=45-49, 7=50-54 , 8=55-59 , 9=60-64, 10= 65-69, 11= 70-74, 12=75-79 ,13=80 o mayores. Variable categ칩rica.

    Education -> escala del 1-6, 1=nunca fue a la escuela o solo kinder, 2=grados 1-8, 3= grados 9-11, 4= grado 12 o graduados de HIgh school, 5= 1-3 de universidad, 6= 4 o mas a;os de universidad. Variable categ칩rica.

    Income -> escala 1-8 1= menos de 10,000, 5= menos de 35,000, 8=75,000 o m치s. Variable categ칩rica.
    """)


elif page =="An치lisis Exploratorio":


    st.header('')

    col_a, col_b, col_c = st.columns([1, 2, 1]) # [Espacio, Gr치fico, Espacio]
    # --- Gr치fica 1: Distribuci칩n por Sexo (usando tu c칩digo) ---
    with col_b:
        st.subheader("Distribuci칩n de la variable objetivo(Diabetes)")

        # Crear una figura de Matplotlib
        fig, ax = plt.subplots()

        # Contar los valores de la columna 'diabetes_01'
        target_counts = datos_diabetes['diabetes_01'].value_counts()

        # Definir etiquetas para el gr치fico
        target_labels = {0.0: 'Sin Diabetes', 1.0: 'Diabetes o Pre-Diabetes'}
        target_counts.index = target_counts.index.map(target_labels)

        # Crear el gr치fico de pastel
        ax.pie(
            target_counts, 
            labels=target_counts.index, 
            autopct='%1.1f%%', # Formato para mostrar porcentajes
            colors=sns.color_palette('RdYlGn_r', len(target_counts)) # Paleta de colores
        )

        ax.set_title("Distribuci칩n de la variable Objetivo")
        st.pyplot(fig)

        
        st.markdown("""
        **Observaci칩n:** Ser치 necesario abordar t칠cnicas de balanceo.
        """)

 

    st.subheader("An치lisis por Sexo y Edad")

    
    col1, col2 = st.columns(2)

    # --- Gr치fica 2: Distribuci칩n de Edad (usando tu c칩digo) ---
    with col1:
                # Creamos la figura de matplotlib PASTEL
        fig1, ax1 = plt.subplots(figsize=(8, 6)) 

        sexo_counts = datos_diabetes['sex'].value_counts() # Asumiendo que tu columna se llama 'Sex'
        sexo_labels = {1: "Masculino", 0: "Femenino"}
        
        sexo_counts.index = sexo_counts.index.map(lambda x: sexo_labels.get(x, "No especificado"))

        ax1.pie(sexo_counts, labels=sexo_counts.index, autopct='%1.1f%%', 
                colors=sns.color_palette('pastel', len(sexo_counts)),
                textprops={'fontsize': 14}) # Hacemos el texto m치s grande
        
        # Usamos st.pyplot() para mostrar la figura de matplotlib en Streamlit
        st.pyplot(fig1)
    with col2:
        
        # Creamos la figura de matplotlib BOXPLOT
        fig2, ax2 = plt.subplots(figsize=(8, 6)) # Creamos otra figura
        
        # Mapeamos los valores de diabetes para que las etiquetas sean claras en la leyenda
        diabetes_labels = {0: 'Sin Diabetes', 1: 'Pre-Diabetes', 2: 'Con Diabetes'}
        # Creamos una copia para no modificar el dataframe original al cambiar los labels
        datos_plot = datos_diabetes.copy()
        binary_labels = {0.0: 'Sin Diabetes', 1.0: 'Diabetes o Pre-Diabetes'}
        datos_plot['diabetes_status'] = datos_plot['diabetes_01'].map(binary_labels) #
        
        sns.boxplot(data=datos_plot, x='sex', y='age', hue='diabetes_status', ax=ax2, palette='viridis') 
        ax2.set_xticklabels(['Femenino', 'Masculino'])
        ax2.set_xlabel("Sexo")
        ax2.set_ylabel("Edad")
        ax2.legend(title='Estado de Diabetes')

        target_labels = {0.0: 'Sin Diabetes', 1.0: 'Diabetes o Pre-Diabetes'}
        target_counts.index = target_counts.index.map(target_labels)


        # Mostramos la figura en Streamlit
        
        st.pyplot(fig2)
        st.write("""
            El conjunto de datos de la BRFSS presenta 


            """)    


    st.subheader("An치lisis de BMI")
    col1, col2 = st.columns(2)
    #BMI
    with col1:
        fig1 = plt.figure(figsize=(8, 6))
        sexo_labels = {1: "Masculino", 0: "Femenino"}

        diabetes_labels = {0.0: 'Negativo a Diabetes', 1.0: 'Positivo a Diabetes'}
        # Creamos la nueva columna 'status' usando el mapeo
        datos_diabetes['status'] = datos_diabetes['diabetes_01'].map(diabetes_labels)     
        sns.boxplot(x='sex', y='bmi', hue='status', data=datos_diabetes, palette='magma')

    # Ajustar los t칤tulos y etiquetas

        plt.title('Distribuci칩n de BMI por Sexo y Diabetes')
        plt.xlabel('sexo')
        plt.xticks(ticks=range(len(sexo_labels)), labels=[sexo_labels[sex] for sex in sorted(sexo_labels.keys())])
        plt.ylabel('bmi')

        # Mostrar la gr치fica
        plt.legend(title='diabetes')
        st.pyplot(fig1)

        st.write("""
            Independientemente del sexo, las personas con mayor BMI tienen mayor problabilidad de tener prediabetes o diabetes, seg칰n los datos.

        """)

    with col2:
        fig2 = plt.figure(figsize=(8, 6))

        df_bmi_60 = datos_diabetes[datos_diabetes['bmi']>=60]
        diabetes_labels = {0.0: 'Negativo a Diabetes', 1.0: 'Positivo a Diabetes'}
        # Creamos la nueva columna 'status' usando el mapeo
        df_bmi_60['status'] = df_bmi_60['diabetes_01'].map(diabetes_labels)           
           
        ##Grafica de frecuencias para bmi mayor a 60
        sns.histplot(data=df_bmi_60, x='bmi', hue='status', kde=False) #bins=k, ax=axes[i], multiple='stack')
            #st.pyplot(fig2)

           # st.write("""
            #Independientemente del sexo, las personas con mayor BMI tienen mayor problabilidad de tener prediabetes o diabetes, seg칰n los datos.

            #""")
        #3 columnas para los boxplot restantes


    st.subheader("Otras variables")
    col_a, col_b, col_c = st.columns(3) # [Espacio, Gr치fico, Espacio]

    with col_a:
        fig1 = plt.figure(figsize=(8, 6))
        sexo_labels = {1: "Masculino", 0: "Femenino"}

        diabetes_labels = {0.0: 'Negativo a Diabetes', 1.0: 'Positivo a Diabetes'}
        # Creamos la nueva columna 'status' usando el mapeo
        datos_diabetes['status'] = datos_diabetes['diabetes_01'].map(diabetes_labels)     
        sns.boxplot(x='sex', y='education', hue='status', data=datos_diabetes, palette='viridis')

        # Ajustar los t칤tulos y etiquetas

        plt.title('Distribuci칩n de Educaci칩n por Sexo y Diabetes')
        plt.xlabel('sexo')
        plt.xticks(ticks=range(len(sexo_labels)), labels=[sexo_labels[sex] for sex in sorted(sexo_labels.keys())])
        plt.ylabel('educaci칩n')

        # Mostrar la gr치fica
        plt.legend(title='diabetes')
        st.pyplot(fig1)

    with col_b:
        fig1 = plt.figure(figsize=(8, 6))
        sexo_labels = {1: "Masculino", 0: "Femenino"}

        diabetes_labels = {0.0: 'Negativo a Diabetes', 1.0: 'Positivo a Diabetes'}
        # Creamos la nueva columna 'status' usando el mapeo
        datos_diabetes['status'] = datos_diabetes['diabetes_01'].map(diabetes_labels)     
        sns.boxplot(x='sex', y='income', hue='status', data=datos_diabetes, palette='viridis')

        # Ajustar los t칤tulos y etiquetas

        plt.title('Distribuci칩n de Ingresos por Sexo y Diabetes')
        plt.xlabel('sexo')
        plt.xticks(ticks=range(len(sexo_labels)), labels=[sexo_labels[sex] for sex in sorted(sexo_labels.keys())])
        plt.ylabel('Ingresos')

        # Mostrar la gr치fica
        plt.legend(title='diabetes')
        st.pyplot(fig1)

    with col_c:
        fig1 = plt.figure(figsize=(8, 6))
        sexo_labels = {1: "Masculino", 0: "Femenino"}

        diabetes_labels = {0.0: 'NO', 1.0: 'SI'}
        # Creamos la nueva columna 'status' usando el mapeo
        datos_diabetes['status'] = datos_diabetes['noDocbcCost'].map(diabetes_labels)     
        sns.boxplot(x='sex', y='income', hue='status', data=datos_diabetes, palette='viridis')

        # Ajustar los t칤tulos y etiquetas

        plt.title('Distribuci칩n de Ingresos por Sexo y noDocbcCost')
        plt.xlabel('sexo')
        plt.xticks(ticks=range(len(sexo_labels)), labels=[sexo_labels[sex] for sex in sorted(sexo_labels.keys())])
        plt.ylabel('Ingresos')

        # Mostrar la gr치fica
        plt.legend(title='noDocbcCost')
        st.pyplot(fig1)

        st.write("""
                *noDocbcCost: el paciente no asistio a cita medica el 칰ltimo mes debido a falta de dinero.
                    

        """)
    st.write("""
        * Las personas con un nivel educativo e ingresos m치s bajos tienden a tener mayor prevalencia de diabetes.

    """)    

    datos_diabetes=datos_diabetes.drop(columns='status')

    correlacion = datos_diabetes.corr()
    figcorr=plt.figure(figsize=(14, 12)) 
    rango_a = 0.2
    rango_b = -0.2

    # Aplicar filtro
    filtro = (correlacion >= rango_a) | (correlacion <= rango_b)
    correlacion_filtrada = correlacion.where(filtro)

    sns.heatmap(correlacion_filtrada, annot=True, cbar=True, cmap="RdYlGn")
    st.pyplot(figcorr)

    st.write("""
        Variables m치s correlacionadas ($correlacion > |0.3| $):

        *PhysHlth y  GenHlth: 0.52

        *PhysHlth y MentHlth: 0.34

        *PhysHlth y DiffWalk: 0.47

        *GenHlth y DiffWalk: 0.45

        *Income y Education: 0.42

        *Income y GenHlth: -0.33

        *Income y DiffWalk: -0.3

        *Age vs HighBP: 0.34

    """)

if page=="Balanceo de clases":

    st.header("Comparaci칩n de T칠cnicas de balanceo")
    
    metrics_unbalanced = pd.read_csv('metrics_logreg_unbalanced.csv', index_col=0)
    metrics_nearmiss = pd.read_csv('metrics_logreg_NearMiss.csv', index_col=0)
    metrics_smote = pd.read_csv('metrics_logreg_SMOTE.csv', index_col=0)
    metrics_smote_samp_5= pd.read_csv('metrics_logreg_SMOTE_samp_0,5.csv', index_col=0)
    metrics_ros = pd.read_csv('metrics_logreg_RandomOverSampler.csv', index_col=0)
    metrics_smotetomek = pd.read_csv('metrics_logreg_SMOTETomek.csv', index_col=0)

    # --- Creaci칩n de la Tabla Comparativa ---
    summary_df = pd.concat([
        metrics_unbalanced['test'],
        metrics_nearmiss['test'],
        metrics_smote['test'],
        metrics_smote_samp_5['test'],
        metrics_ros['test'],
        metrics_smotetomek['test']

    ], axis=1)
        
    summary_df.columns = ['Datos Desbalanceados','NearMiss', 'SMOTE', 'SMOTE (sample_strategy=0.5)','RandomOverSampler', 'SMOTETomek']

    st.subheader("Tabla Comparativa de Rendimiento (en Test)")
    st.markdown("Se implementan algunas t칠cnicas de balanceo, y se evalua utilizando una Regresi칩n Log칤stica.")
    st.dataframe(summary_df)

    st.markdown("""
    **Se observa una ligera mejora en F1 con t칠cnicas de balanceo como SMOTE Y Random OverSampler** 
    """)

    st.divider()

        # --- Graficas
    st.subheader("Visualizaci칩n por Caso")

    with st.expander("Ver Gr치ficas para Datos Desbalanceados"):
        try:
            with open('fig_logreg_unbalanced.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'figure_logreg_unbalanced.pkl'.")

    st.markdown("*Near Miss es una t칠cnica de submuestreo de la clase mayoritaria, elimina las observaciones mas cercanas a las observaciones de la clase minoritaria.")
    with st.expander("Ver Gr치ficas para NearMiss"):
        try:
            with open('fig_logreg_NearMiss.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'figure_logreg_NearMiss.pkl'.")
    st.markdown("SMOTE crea elementos sint칠ticos de la clase minoritaria.")
    with st.expander("Ver Gr치ficas para SMOTE"):
        try:
            with open('fig_logreg_SMOTE.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'figure_logreg_SMOTE.pkl'.")
    st.markdown("El par치metro sample_strategy = 0.5, hace que el n칰mero de elementos de la clase minoritaria sea la mitad de la clase mayoritaria.")
    with st.expander("Ver Gr치ficas para SMOTE (sample_strategy=0.5)"):
        try:
            with open('fig_logreg_SMOTE_samp_0,5.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'figure_logreg_SMOTE_samp_0,5.pkl'.")
    st.markdown("RandomOverSampler replica observaciones de la clase minoritaria ya existentes.")
    with st.expander("Ver Gr치ficas para RandomOverSampler"):
        try:
            with open('fig_logreg_RandomOverSampler.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_logreg_RandomOverSampler.pkl'.")
    st.markdown("SMOTETomek crea elementos sint칠ticos de la clase minoritaria, y elimina los elementos de la clase mayoritaria cercanos a elementos de la clase minoritaria.")
    with st.expander("Ver Gr치ficas para SMOTETomek"):
        try:
            with open('fig_logreg_SMOTETomek.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'figure_logreg_SMOTETomek.pkl'.")

    st.markdown("Observaciones:\n\n" \
                
                "* Tanto en SMOTE como en Random Over Sampler, se observa un sobreentrenamiento en las gr치ficas de F1 y PRC, indicando que no se puede generalizar los patrones de la clase minoritaria.\n\n" \
                "* El umbral de decisi칩n de 0.5 (punto rojo) se desplaz칩 a la derecha en la curva de PRC, para ambos met칩dos de balanceo, es decir, aumento recall en ambos casos." \
                "Esto es un indicador de que disminuyeron los Falsos negativos, un tipo de error que es importante mantener controlado en los casos m칠dicos.\n\n" \
                "*Se observa un mejor recall en RandomOverSampler y SMOTE. ")

elif page=="Importancia de caracter칤sticas":

    st.markdown("Utilizamos el modelo de ExtraTreeClassificator, para asignarle una importancia a cada caracter칤stica en base a su aportaci칩n en la reducci칩n de impureza." \
    "  Entrenamos un modelo agregando caracter칤sticas, empezando con las de mayor importancia, hasta maximixar F1.")

    scenario_choice = st.selectbox(
        "Selecciona el escenario para analizar:",
        ("Sin Balanceo (Datos Originales)", "Con Balanceo (RandomOverSampler)")
    )

    # --- L칩gica para cargar los archivos correctos ---
    if scenario_choice == "Sin Balanceo (Datos Originales)":
        features_file = 'feature_importances_extratreeclassificator.csv'
        results_file = 'results_extratreeclassificator.csv'
    else: # Con Balanceo
        features_file = 'feature_importances_extratreeclassificator_RandOverSampler.csv'
        results_file = 'results_extratreeclassificator_RandOverSampler.csv'

    try:
        # Cargar los datos desde los archivos CSV
        feature_importances = pd.read_csv(features_file)
        results_df = pd.read_csv(results_file)

        st.subheader(f"Resultados para: {scenario_choice}")

        # --- Visualizaci칩n 1: Gr치fico de Barras de Importancia ---
        top_features = feature_importances.head(15)

        fig1, ax1 = plt.subplots(figsize=(12, 8))
        sns.barplot(x="Importance", y="Feature", data=top_features, palette="rocket", ax=ax1)
        ax1.set_title("Top 15 Caracter칤sticas M치s Predictivas", fontsize=16)
        ax1.set_xlabel("Importancia (calculada con ExtraTrees)", fontsize=12)
        ax1.set_ylabel("Caracter칤stica", fontsize=12)
        plt.tight_layout()
        st.pyplot(fig1)
        
        st.divider()

        # --- Visualizaci칩n 2: Gr치fico de L칤neas de Rendimiento vs. N춿 de Caracter칤sticas ---
        st.subheader("B칰squeda del N칰mero 칍ptimo de Caracter칤sticas")

        col1, col2 = st.columns([2, 1])

        with col1:
            fig2, ax2 = plt.subplots(figsize=(10, 6))
            # Usaremos la columna 'F1' que ya hab칤as calculado
            metric_to_plot = 'F1'
            ax2.plot(results_df["Number of Features"], results_df[metric_to_plot], marker="o", linestyle="--")
            ax2.set_xlabel("N칰mero de Caracter칤sticas Utilizadas")
            ax2.set_ylabel(f"{metric_to_plot} Score")
            ax2.set_title(f"Rendimiento ({metric_to_plot}) vs. N칰mero de Caracter칤sticas")
            
            # Encontrar y marcar el punto 칩ptimo basado en F1
            optimal_row = results_df.loc[results_df[metric_to_plot].idxmax()]
            optimal_num = int(optimal_row["Number of Features"])
            max_metric = optimal_row[metric_to_plot]
            
            ax2.axvline(x=optimal_num, color="r", linestyle="--", label=f"칍ptimo: {optimal_num} feats.")
            ax2.legend()
            st.pyplot(fig2)

        with col2:
            st.write("") # Espacio para alinear
            st.metric(
                label=f"N칰mero 칍ptimo de Caracter칤sticas (por {metric_to_plot})",
                value=f"{optimal_num}"
            )
            st.metric(
                label=f"{metric_to_plot} Score M치ximo",
                value=f"{max_metric:.4f}"
            )
        st.markdown("Despu칠s de aplicar t칠cnicas de balanceo, se necesitaron menos caracter칤sticas para maximizar F1.")

    except FileNotFoundError as e:
        st.error(f"Error: No se encontr칩 el archivo necesario: {e.filename}")
        
elif page == "Resultados: 츼rboles de decisi칩n":
    st.header("츼rboles de decisi칩n")
    st.write("""

    A continuaci칩n, comparamos su rendimiento en tres casos:
    1.  **Datos Desbalanceados:**
    2.  **Balanceo con RandomOverSampler:**
    3. **Balanceo con SMOTE**
    4.  **4 mejores caracter칤sticas usando RandomOverSampler :** 
    """)

    # Cargar datos
    try:
        metrics_dt_unbalanced = pd.read_csv('modelos_dashboard_dt/metrics_dt_unbalanced.csv', index_col=0)
        metrics_dt_ros = pd.read_csv('modelos_dashboard_dt/metrics_dt_RandOvSamp.csv', index_col=0)
        metrics_dt_smote = pd.read_csv('modelos_dashboard_dt/metrics_dt_SMOTE.csv', index_col=0)
        metrics_dt_best4 = pd.read_csv('modelos_dashboard_dt/metrics_dt_RandOvSamp_best4.csv', index_col=0)

        # concatenar graficas
        summary_dt_df = pd.concat([
            metrics_dt_unbalanced['test'],
            metrics_dt_ros['test'],
            metrics_dt_smote['test'],
            metrics_dt_best4['test']
        ], axis=1)
        
        # Renombramos las columnas para mayor claridad
        summary_dt_df.columns = ['DT Desbalanceado', 'DT con RandomOverSampler','DT con SMOTE', 'DT con RandomOverSampler (Top 4)']

        st.subheader("Tabla comparativa de rendimiento de 츼rboles de decisi칩n (en Test)")
        st.dataframe(summary_dt_df)

    except FileNotFoundError:
        st.error("Error al cargar los archivos de m칠tricas de DT. Aseg칰rate de que todos los archivos .csv est칠n en tu repositorio de GitHub.")

    st.divider()

    # Secci칩n de las graficas
    st.subheader("Visualizaci칩n detallada escenario de 츼rboles de decisi칩n")

    with st.expander("Ver gr치ficas para DT con datos desbalanceados"):
        try:
            with open('modelos_dashboard_dt/fig_dt_unbalanced.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_dt_unbalanced.pkl'.")

    with st.expander("Ver Gr치ficas para 치rboles de decisi칩n con RandomOverSampler"):
        try:
            with open('modelos_dashboard_dt/fig_dt_RandOvSamp.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_dt_RandOvSamp.pkl'.")
    with st.expander("Ver Gr치ficas para 치rboles de decisi칩n con SMOTE"):
        try:
            with open('modelos_dashboard_dt/fig_dt_SMOTE.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_dt_SMOTE.pkl'.")

    with st.expander("Ver gr치ficas para DT balanceado (Top 4)"):
        try:
            with open('modelos_dashboard_dt/fig_dt_RandOvSamp_best4.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_dt_RandOvSamp_best4.pkl'.")

    st.markdown("En 치rboles de decisi칩n, ambas t칠cnicas de balanceo de clases no logran mejorar el rendimientodel modelo, y generan un gran" \
    " sobreajuste. Utilizando 칰nicamente las 4 mejores caracter칤sticas observamos un mejor rendimiento. ")

elif page == "Resultados: Random Forest":
    st.header("Random Forest")
    st.write("""

    A continuaci칩n, comparamos su rendimiento en tres casos:
    1.  **Datos Desbalanceados:**
    2.  **Balanceo con RandomOverSampler:**
    3.  **Balanceo con SMOTE**       
    4.  **4 mejores caracter칤sticas usando RandomOverSampler :** 
    """)

    # Cargar datos
    try:
        metrics_rf_unbalanced = pd.read_csv('modelos_dashboard_RandForest/metrics_RandForest_unbalanced.csv', index_col=0)
        metrics_rf_ros = pd.read_csv('modelos_dashboard_RandForest/metrics_RandForest_RandOvSampler.csv', index_col=0)
        metrics_rf_smote = pd.read_csv('modelos_dashboard_RandForest/metrics_RandForest_SMOTE.csv', index_col=0)
        metrics_rf_best4 = pd.read_csv('modelos_dashboard_RandForest/metrics_RandForest_RandOvSampler_best4.csv', index_col=0)

        # concatenar graficas
        summary_rf_df = pd.concat([
            metrics_rf_unbalanced['test'],
            metrics_rf_ros['test'],
            metrics_rf_smote['test'],
            metrics_rf_best4['test']
        ], axis=1)
        
        # Renombramos las columnas para mayor claridad
        summary_rf_df.columns = ['RF Desbalanceado', 'RF con RandomOverSampler', 'RF con SMOTE','RF con RandomOverSampler (Top 4)']

        st.subheader("Tabla comparativa de rendimiento de Random Forest (en Test)")
        st.dataframe(summary_rf_df)

        st.markdown("""
        
        """)

    except FileNotFoundError:
        st.error("Error al cargar los archivos de m칠tricas de Random Forest. Aseg칰rate de que todos los archivos .csv est칠n en tu repositorio de GitHub.")

    st.divider()

    # Secci칩n de las graficas
    st.subheader("Visualizaci칩n detallada escenario de Random Forest")

    with st.expander("Ver gr치ficas para RF con datos desbalanceados"):
        try:
            with open('modelos_dashboard_RandForest/fig_RandForest_unbalanced.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_RandForest_unbalanced.pkl'.")

    with st.expander("Ver Gr치ficas para RF con RandomOverSampler"):
        try:
            with open('modelos_dashboard_RandForest/fig_RandForest_RandOvSampler.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_RandForest_RandOvSampler.pkl'.")
    with st.expander("Ver Gr치ficas para RF con SMOTE"):
        try:
            with open('modelos_dashboard_RandForest/fig_RandForest_SMOTE.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_RandForest_SMOTE.pkl'.")
    with st.expander("Ver gr치ficas para RF balanceado (Top 4)"):
        try:
            with open('modelos_dashboard_RandForest/fig_RandForest_RandOvSampler_best4.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_RandForest_RandOvSampler_best4.pkl'.")
    st.markdown("Observamos que, despues de tratar el desbalance con dos t칠cnias distintas, los modelos se sobreajustan. Las t칠cnicas " \
    "de balanceo de clases no ayudan a que Random Forest pueda aprender sobre los pacientes positivos." \
    "Esperar칤amos que SMOTE ayudar치 a generar mayor conocimiento que Random Over Sampler,  ya que genera muestras sint칄ticas similares, dotando a los datos de mayor variedad," \
    "pero observamos un mayor sobreajuste con esta t칠cnica.")

elif page == "Resultados: Perceptr칩n multicapa":
    st.header("Redes neuronales")
    st.write("""

    A continuaci칩n, comparamos su rendimiento en tres casos:
    1.  **Datos Desbalanceados:**
    2.  **Balanceo con RandomOverSampler:**
    3.  **4 mejores caracter칤sticas usando RandomOverSampler :** 
    """)

    # Cargar datos
    try:
        metrics_nn_unbalanced = pd.read_csv('modelos_dashboard_redes/metrics_NN_unbalanced.csv', index_col=0)
        metrics_nn_ros = pd.read_csv('modelos_dashboard_redes/metrics_NN_RandOvSampler.csv', index_col=0)
        metrics_nn_best4 = pd.read_csv('modelos_dashboard_redes/metrics_NN_RandOvSampler_best4.csv', index_col=0)

        # concatenar graficas
        summary_nn_df = pd.concat([
            metrics_nn_unbalanced['test'],
            metrics_nn_ros['test'],
            metrics_nn_best4['test']
        ], axis=1)
        
        # Renombramos las columnas para mayor claridad
        summary_nn_df.columns = ['PM Desbalanceado', 'PM con RandomOverSampler', 'PM con RandomOverSampler (Top 4)']

        st.subheader("Tabla comparativa de rendimiento de Perceptr칩n Multicapa (en Test)")
        st.dataframe(summary_nn_df)

        st.markdown("""
        
        """)

    except FileNotFoundError:
        st.error("Error al cargar los archivos de m칠tricas de NN. Aseg칰rate de que todos los archivos .csv est칠n en tu repositorio de GitHub.")

    st.divider()

    # Secci칩n de las graficas
    st.subheader("Visualizaci칩n detallada escenario de Perceptr칩n multicapa")

    with st.expander("Ver gr치ficas para Perceptr칩n multicapa con datos desbalanceados"):
        try:
            with open('modelos_dashboard_redes/fig_NN_unbalanced.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_NN_unbalanced.pkl'.")

    with st.expander("Ver Gr치ficas para PM con RandomOverSampler"):
        try:
            with open('modelos_dashboard_redes/fig_NN_RandOvSampler.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_NN_RandOvSampler.pkl'.")

    with st.expander("Ver gr치ficas para Perceptr칩n multicapa balanceado (Top 4)"):
        try:
            with open('modelos_dashboard_redes/fig_NN_RandOvSampler_best4.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_NN_RandOvSampler_best4.pkl'.")

elif page == "Resultados: Random Forest balanceado":
    st.header("RF balanceado")
    st.write("""

    A continuaci칩n, comparamos su rendimiento en los siguientes casos:
    1.  ** Todas las caracter칤sticas:**
    2.  

    """)

    # Cargar datos
    try:
        metrics_nn_unbalanced = pd.read_csv('BalancedRandomForest/metrics_balancedRandomForest.csv', index_col=0)
        #metrics_nn_ros = pd.read_csv('BalancedRandomForest/metrics_NN_RandOvSampler.csv', index_col=0)
        #metrics_nn_best4 = pd.read_csv('modelos_dashboard_redes/metrics_NN_RandOvSampler_best4.csv', index_col=0)

        # concatenar graficas
        summary_nn_df = pd.concat([
            metrics_nn_unbalanced['test']#,
            #metrics_nn_ros['test'],
            #metrics_nn_best4['test']
        ], axis=1)
        
        # Renombramos las columnas para mayor claridad
        summary_nn_df.columns = ['Balanced Random Forest']

        st.subheader("Tabla comparativa de rendimiento de BAlanced Random Forest (en Test)")
        st.dataframe(summary_nn_df)

        st.markdown("""
        
        """)

    except FileNotFoundError:
        st.error("Error al cargar los archivos de m칠tricas de NN. Aseg칰rate de que todos los archivos .csv est칠n en tu repositorio de GitHub.")

    st.divider()

    # Secci칩n de las graficas
    st.subheader("Visualizaci칩n detallada escenario de Balanced Random Forest")

    with st.expander("Ver gr치ficas para Balanced Random Forest"):
        try:
            with open('BalancedRandomForest/fig_balancedRandomForest.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_balancedRandomForest.pkl'.")

    #with st.expander("Ver Gr치ficas para PM con RandomOverSampler"):
    #    try:
    #        with open('modelos_dashboard_redes/fig_NN_RandOvSampler.pkl', 'rb') as f:
    #            fig = pickle.load(f)
    #            st.pyplot(fig)
    #    except FileNotFoundError:
    #        st.warning("No se encontr칩 el archivo 'fig_NN_RandOvSampler.pkl'.")

    #with st.expander("Ver gr치ficas para Perceptr칩n multicapa balanceado (Top 4)"):
    #    try:
    #        with open('modelos_dashboard_redes/fig_NN_RandOvSampler_best4.pkl', 'rb') as f:
    #            fig = pickle.load(f)
    #            st.pyplot(fig)
    #    except FileNotFoundError:
    #        st.warning("No se encontr칩 el archivo 'fig_NN_RandOvSampler_best4.pkl'.")
    st.markdown("Balanced Random Forest utiliza t칠cnicas de submuestreo aleatorio para que cada 치rbol entrene con una muestra de datos equilibrada.\n" \
    "* En este caso, esperamos reducir el sobreajuste que presento Random Forest original con RandomOverSampler (AP=0.82 en train vs AP= 0.45 en test)\n" \
    "* Resultado: Se redujo el sobre ajuste (AP=0.72 vs AP=0.45), pero nose mejoro en test.")

elif page == "Resultados: XGBoost":
    st.header("XGBoost")
    st.write("""

    A continuaci칩n, comparamos su rendimiento en tres casos:
    1.  **Datos Desbalanceados:**
    2.  **Balanceo con "pos_class_weight":**
    3.  **4 mejores caracter칤sticas:** 
    """)

    # Cargar datos
    try:
        metrics_nn_unbalanced = pd.read_csv('xgboost/metrics_xgboost_unbalanced.csv', index_col=0)
        metrics_nn_ros = pd.read_csv('xgboost/metrics_xgboost_balanced.csv', index_col=0)
        metrics_nn_best4 = pd.read_csv('xgboost/metrics_xgboost_balanced_best4.csv', index_col=0)

        # concatenar graficas
        summary_nn_df = pd.concat([
            metrics_nn_unbalanced['test'],
            metrics_nn_ros['test'],
            metrics_nn_best4['test']
        ], axis=1)
        
        # Renombramos las columnas para mayor claridad
        summary_nn_df.columns = ['XGBoost Desbalanceado', 'XGBoost Balanceado con pos_class_weight', 'XGBoost (Top 4)']

        st.subheader("Tabla comparativa de rendimiento XGBoosy (en Test)")
        st.dataframe(summary_nn_df)

        st.markdown("""
        
        """)

    except FileNotFoundError:
        st.error("Error al cargar los archivos de m칠tricas de NN. Aseg칰rate de que todos los archivos .csv est칠n en tu repositorio de GitHub.")

    st.divider()

    # Secci칩n de las graficas
    st.subheader("Visualizaci칩n detallada escenario de  XGBoost")

    with st.expander("Ver gr치ficas para XGBoost con datos desbalanceados"):
        try:
            with open('xgboost/fig_xgboost_unbalanced.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_xgboost_unbalanced.pkl'.")

    st.markdown("El modelo sin tratar el balance de los datos, presenta un sobreajuste. Se observa un AP de 0.42 para test y 0.68 para train.")

    with st.expander("Ver Gr치ficas para XGBoost balanceado"):
        try:
            with open('xgboost/fig_xgboost_balanced.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_xgboost_balanced.pkl'.")
    
    st.markdown("Manejando el desbalance asignandole un peso a las observaciones positivas, se reduce el sobreajuste, ademas de subir el AP a 0.46 en test.")

    with st.expander("Ver gr치ficas para XGBoost (Top 4)"):
        try:
            with open('xgboost/fig_xgboost_balanced_best4.pkl', 'rb') as f:
                fig = pickle.load(f)
                st.pyplot(fig)
        except FileNotFoundError:
            st.warning("No se encontr칩 el archivo 'fig_xgboost_balanced_best4.pkl'.")

    st.markdown("Al utilizar 칰nicamente las mejores 4 cracter칤sticas, la diferencia entre train y test disminuye, pero tambi칠n lo hace AP.")

elif page == "Conclusiones Generales":
    st.header("Conclusiones:")

    st.markdown("El proyecto tuvo como objetvo examinar los datos de BRFSS 2015 para ver cuales son los mayores factores de reisgo en diabetes, y " \
    " probar si con est치 informaci칩n es posible crear un modelo que clasifique a los pacientes adecuadamente. Concluimso con los siguientes puntos: \n" \
    "* Ning칰n clasificador logr칩 superar el 치rea bajo la curva de Precision-recall de 0.5, incluso utilizando t칠cnicas de balanceo como Random Over Sampler o SMOTE.\n" \
    "* Se probaron clasificadores que manejan el desbalance de clases, como Balanced Random Forest y XGboost, siendo el segundo el de mejor desempe침o, ya que redujo el sobreajuste.\n" \
    "*  Todos los clasificadores, al aplicar t칠cnicas de balanceo, mejoran en Recall, por lo que hay una reducci칩n de Falsos negativos.\n" \
    "* Los factores de riesgo que m치s influyen son el BMI, la edad,, ingresos y genHlth. \n\n" \
    "Es necesario recolectar m치s datos para poder dotar de mayor capacidad de generalizaci칩n sobre la clase positiva a los modelos."
    
    )



    # --- Mostrando los Datos ---
    #st.header('Cabeza del dataset')
    #st.dataframe(datos_diabetes.head())

